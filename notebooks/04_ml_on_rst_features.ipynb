{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# from collections import Counter\n",
    "\n",
    "# === Define the path to the auxiliary modules ===\n",
    "ROOT = Path.cwd().parent\n",
    "SRC = (ROOT / \"src\").resolve()\n",
    "\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "import importlib\n",
    "import analysis.restructure as restr\n",
    "import analysis.pipelines as plns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00225bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = Path.home()\n",
    "DATA_DIR = (HOME / \"My Drive\" / \"_VectorData\" / \"projects\" / \"identifying_depression_with_rst\" / \"data\").resolve(strict=True)\n",
    "\n",
    "corpus_path = DATA_DIR / \"interim\"\n",
    "corpus_file = corpus_path / \"preprocesssed_corpora.json\"\n",
    "\n",
    "with open(corpus_file, \"r\") as file:\n",
    "    corpora = json.load(file)\n",
    "\n",
    "rst_data_path = DATA_DIR / \"interim\"\n",
    "rst_data_file = rst_data_path / \"rst_data_gumrrg.json\"\n",
    "# rst_data_file = rst_data_path / \"rst_data_rstreebank.json\"\n",
    "\n",
    "with open(rst_data_file, \"r\") as file:\n",
    "    rst_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae46f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4564b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_NAME_1 = \"ked\"\n",
    "CORPUS_NAME_2 = \"kldl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc0d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora[CORPUS_NAME_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora[CORPUS_NAME_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The structure of the data in rst_data is guided by this strucutre of the dictionary that was used to save the data to a json file\n",
    "\"\"\"\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"all_features\"] = all_features_1\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"all_features_neg\"] = all_features_neg_1\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"all_features_pos\"] = all_features_pos_1\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"relations_pos\"] = relations_pos_1\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"relations_neg\"] = relations_neg_1\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"all_relations\"] = list(all_relations_1)\n",
    "\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"all_features\"] = all_features_2\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"all_features_neg\"] = all_features_neg_2\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"all_features_pos\"] = all_features_pos_2\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"relations_pos\"] = relations_pos_2\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"relations_neg\"] = relations_neg_2\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"all_relations\"] = list(all_relations_2)\n",
    "\"\"\"\n",
    "\n",
    "# Example:\n",
    "rst_data[CORPUS_NAME_1][\"relations_pos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rst_data[CORPUS_NAME_2][\"all_features_pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22878c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rst_data[CORPUS_NAME_2][\"all_features_neg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4d8b0",
   "metadata": {},
   "source": [
    "## Reload the modules if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case we need to reload the module\n",
    "restr = importlib.reload(restr)\n",
    "plns = importlib.reload(plns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c691f3",
   "metadata": {},
   "source": [
    "## Xy with all the features\n",
    "(apart from raw nuclearity pattern counts -- they are removed manually)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71eabfa",
   "metadata": {},
   "source": [
    "### A first corpus to Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22213da",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data = restr.get_data_vectors(rst_data[CORPUS_NAME_1][\"all_relations\"], rst_data[CORPUS_NAME_1][\"all_features_neg\"])\n",
    "pos_data = restr.get_data_vectors(rst_data[CORPUS_NAME_1][\"all_relations\"], rst_data[CORPUS_NAME_1][\"all_features_pos\"])\n",
    "\n",
    "Xy_1 = restr.build_feature_matrix(pos_data, neg_data, features=None)\n",
    "\n",
    "\n",
    "Xy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062322ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Xy_1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f19e4f7",
   "metadata": {},
   "source": [
    "### A second corpus to Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2aba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data = restr.get_data_vectors(rst_data[CORPUS_NAME_2][\"all_relations\"], rst_data[CORPUS_NAME_2][\"all_features_neg\"])\n",
    "pos_data = restr.get_data_vectors(rst_data[CORPUS_NAME_2][\"all_relations\"], rst_data[CORPUS_NAME_2][\"all_features_pos\"])\n",
    "\n",
    "Xy_2 = restr.build_feature_matrix(pos_data, neg_data, features=None)\n",
    "\n",
    "Xy_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9272b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Xy_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a8b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xy to be used in the pipelines below:\n",
    "\n",
    "Xy = pd.concat([Xy_1, Xy_2], ignore_index=True)\n",
    "# Xy = Xy_2\n",
    "# Xy = Xy_1\n",
    "\n",
    "Xy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168c56a",
   "metadata": {},
   "source": [
    "### Dropping raw counts for nuclearity patterns (to keep only relational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a02fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"nucl_NN\", \"nucl_NS\", \"nucl_SN\", \"nucl_pattern\"]  # last one just in case (if for some reason it is still there)\n",
    "Xy = Xy.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b089761",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9f6b46",
   "metadata": {},
   "source": [
    "### Regular LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xy is the DataFrame from build_feature_matrix(...), with label already 0/1 as int's\n",
    "# L2\n",
    "\n",
    "X_train_s, X_test_s, y_train, y_test, scaler, X_train, X_test = plns.prep_train_test(Xy)\n",
    "\n",
    "clf = plns.train_logreg(X_train_s, y_train)\n",
    "report_df, cm, coef_df = plns.evaluate_classifier(\n",
    "    clf,\n",
    "    X_test_s,\n",
    "    y_test,\n",
    "    feature_names=list(X_train.columns),  # <- critical: order matches training\n",
    ")\n",
    "\n",
    "\n",
    "print(report_df.round(3))\n",
    "print(cm)\n",
    "print(coef_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda33c02",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso/L1\n",
    "\n",
    "X_train_s, X_test_s, y_train, y_test, scaler, X_train, X_test = plns.prep_train_test(Xy)\n",
    "\n",
    "clf = plns.train_logreg_l1(X_train_s, y_train)\n",
    "report_df, cm, coef_df = plns.evaluate_classifier(\n",
    "    clf,\n",
    "    X_test_s,\n",
    "    y_test,\n",
    "    feature_names=list(X_train.columns),\n",
    ")\n",
    "\n",
    "\n",
    "print(report_df.round(3))\n",
    "print(cm)\n",
    "print(coef_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce7223f",
   "metadata": {},
   "source": [
    "### LogReg with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25684413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold CV with L2 (default)\n",
    "folds, summary, _ = plns.cross_validate_logreg(Xy, k=5, use_l1=False)\n",
    "print(\"L2 Results:\")\n",
    "print(folds.round(3))\n",
    "print(summary.round(3))\n",
    "print(\"\")\n",
    "\n",
    "# K-fold CV with L1\n",
    "folds_l1, summary_l1, models = plns.cross_validate_logreg(Xy, k=5, use_l1=True, C=1.0, return_models=True)\n",
    "print(\"L1 Results:\")\n",
    "print(folds_l1.round(3))\n",
    "print(summary_l1.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c10bac",
   "metadata": {},
   "source": [
    "### HistGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e822cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = plns.prep_train_test_tabular(Xy, label_col=\"label\")\n",
    "\n",
    "hgb = plns.train_hgb(X_train, y_train, max_depth=None, learning_rate=0.06, max_iter=400)\n",
    "\n",
    "report_df, cm, imp_df, metrics = plns.evaluate_hgb(hgb, X_test, y_test, feature_names=list(X_train.columns))\n",
    "\n",
    "print(report_df.round(3))\n",
    "print(\"\")\n",
    "print(cm)\n",
    "print(\"\")\n",
    "print(metrics)            # {'roc_auc': ..., 'pr_auc': ...}\n",
    "print(\"\")\n",
    "print(imp_df.head(15))    # top features by permutation importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ef303",
   "metadata": {},
   "source": [
    "## Xy_aug: Run on augmented/refined features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a724ae",
   "metadata": {},
   "source": [
    "### Prep Xy_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4536d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a first corpus\n",
    "\n",
    "rst_pos = rst_data[CORPUS_NAME_1][\"all_features_pos\"]\n",
    "rst_neg = rst_data[CORPUS_NAME_1][\"all_features_neg\"]\n",
    "rst_docs_all_1 = list(rst_pos) + list(rst_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a second corpus\n",
    "\n",
    "rst_pos = rst_data[CORPUS_NAME_2][\"all_features_pos\"]\n",
    "rst_neg = rst_data[CORPUS_NAME_2][\"all_features_neg\"]\n",
    "rst_docs_all_2 = list(rst_pos) + list(rst_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small helper to calculate the extra features and concat them to the exisitng Xy\n",
    "\n",
    "def augment_rst_features(docs_all, Xy):\n",
    "\n",
    "    # Turning raw RST into the 6 \"engineered\" features:\n",
    "    # (depth_per_edu, rel_entropy, rel_top2_dom, edu_len_mean, edu_len_std, edu_len_p90)\n",
    "    df_extra = restr.extra_rst_features_from_raw(docs_all)\n",
    "\n",
    "    assert len(docs_all) == len(Xy), \"row count mismatch (ordering/alignment problem)\"\n",
    "    assert set(df_extra.columns) == {\n",
    "        \"depth_per_edu\",\"rel_entropy\",\"rel_top2_dom\",\"edu_len_mean\",\"edu_len_std\",\"edu_len_p90\"\n",
    "    }\n",
    "\n",
    "    Xy_aug = pd.concat([Xy.reset_index(drop=True), df_extra.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return Xy_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If concatenating:\n",
    "# Xy_aug = pd.concat([augment_rst_features(rst_docs_all_1, Xy_1), augment_rst_features(rst_docs_all_2, Xy_2)], ignore_index = True)\n",
    "\n",
    "# If using just one corpus:\n",
    "# Xy_aug = augment_rst_features(rst_docs_all_1, Xy)\n",
    "Xy_aug = augment_rst_features(rst_docs_all_2, Xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b77953",
   "metadata": {},
   "source": [
    "### Regular LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s, X_test_s, y_train, y_test, scaler, X_train, X_test = plns.prep_train_test(Xy_aug)\n",
    "clf = plns.train_logreg(X_train_s, y_train)\n",
    "report_df, cm, coef_df = plns.evaluate_classifier(clf, X_test_s, y_test, feature_names=list(X_train.columns))\n",
    "\n",
    "print(report_df.round(3))\n",
    "print(cm)\n",
    "print(coef_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa4af2",
   "metadata": {},
   "source": [
    "### LogReg + Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b435ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold CV with L2 (default)\n",
    "folds, summary, _ = plns.cross_validate_logreg(Xy_aug, k=5, use_l1=False)\n",
    "print(\"L2 Results\")\n",
    "print(folds.round(3))\n",
    "print(summary.round(3))\n",
    "print(\"\")\n",
    "\n",
    "# K-fold CV with L1 (sparser)\n",
    "folds_l1, summary_l1, models = plns.cross_validate_logreg(Xy_aug, k=5, use_l1=True, C=1.0, return_models=True)\n",
    "print(\"L1 Results\")\n",
    "print(folds_l1.round(3))\n",
    "print(summary_l1.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7c0c2",
   "metadata": {},
   "source": [
    "### HistGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aad99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = plns.prep_train_test_tabular(Xy_aug, label_col=\"label\")\n",
    "\n",
    "hgb = plns.train_hgb(X_train, y_train, max_depth=None, learning_rate=0.06, max_iter=400)\n",
    "\n",
    "report_df, cm, imp_df, metrics = plns.evaluate_hgb(hgb, X_test, y_test, feature_names=list(X_train.columns))\n",
    "\n",
    "print(report_df.round(3))\n",
    "print(\"\")\n",
    "print(cm)\n",
    "print(\"\")\n",
    "print(metrics)            # {'roc_auc': ..., 'pr_auc': ...}\n",
    "print(\"\")\n",
    "print(imp_df.head(15))    # top features by permutation importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0278cf",
   "metadata": {},
   "source": [
    "## Xy_final: augmented, rare relations removed (This is just a test / proof of concept for now)\n",
    "(In case of the data used here there seems to be no added benefit from removing the potential \"noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f1ffd",
   "metadata": {},
   "source": [
    "### Prep Xy_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_REL = {\n",
    "    \"label\",\n",
    "    # structure / sizes\n",
    "    \"tree_depth\",\"num_edus\",\"depth_per_edu\",\n",
    "    # nuclearity\n",
    "    \"nucl_NN\",\"nucl_NS\",\"nucl_SN\",\n",
    "    \"nucl_NN_relprop\",\"nucl_NS_relprop\",\"nucl_SN_relprop\",\n",
    "    # engineered stats\n",
    "    \"rel_entropy\",\"rel_top2_dom\",\n",
    "    \"edu_len_mean\",\"edu_len_std\",\"edu_len_p90\",\n",
    "    # if present already, donâ€™t let collapse touch it:\n",
    "    \"rel_OTHER\",\n",
    "}\n",
    "\n",
    "REL_COLS = [c for c in Xy_aug.columns if c not in NON_REL]\n",
    "\n",
    "# This is just to preview what it WOULD look like\n",
    "Xy_final = restr.collapse_rare_relations_df(\n",
    "    Xy_aug, REL_COLS, avg_prop_min=0.01, other_col=\"rel_OTHER\"\n",
    ")\n",
    "\n",
    "Xy_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1722c1d",
   "metadata": {},
   "source": [
    "### Regular LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling on the collapserare class to only collapse rare relations BASED on the traning set ONLY\n",
    "\n",
    "rare = plns.CollapseRareRels(min_docs=100, other_col=\"rel_OTHER\", rel_cols=REL_COLS)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = plns.prep_train_test_tabular(Xy_aug, label_col=\"label\") # scale later separately\n",
    "\n",
    "rare.fit(X_tr)          # fit on TRAIN ONLY\n",
    "X_tr2 = rare.transform(X_tr)\n",
    "X_te2 = rare.transform(X_te)\n",
    "\n",
    "assert list(X_tr2.columns) == list(X_te2.columns)\n",
    "print(\"Cols/rels that were kept:\", rare.keep_cols_)            # kept relations\n",
    "print(\"Cols/rels that were removed:\", rare.collapsed_cols_)  # collapsed relations\n",
    "print(\"\")\n",
    "\n",
    "nz = X_tr2.loc[:, X_tr2.var(axis=0) > 1e-12]\n",
    "X_te2 = X_te2[nz.columns]\n",
    "X_tr2 = nz\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_tr2)\n",
    "X_tr2s = scaler.transform(X_tr2)\n",
    "X_te2s = scaler.transform(X_te2)\n",
    "\n",
    "# The rest is business as usual\n",
    "clf = plns.train_logreg(X_tr2s, y_tr)\n",
    "\n",
    "report_df, cm, coef_df = plns.evaluate_classifier(\n",
    "    clf,\n",
    "    X_te2s,\n",
    "    y_te,\n",
    "    feature_names=list(X_tr2.columns),\n",
    ")\n",
    "\n",
    "print(report_df.round(3))\n",
    "print(\"\")\n",
    "print(cm)\n",
    "print(\"\")\n",
    "print(coef_df.sort_values(\"odds_ratio\", ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58a4458",
   "metadata": {},
   "source": [
    "### HistGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d99a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_hgb = plns.CollapseRareRels(min_docs=100, other_col=\"rel_OTHER\", rel_cols=REL_COLS)\n",
    "\n",
    "X_tr_hgb, X_te_hgb, y_tr_hgb, y_te_hgb = plns.prep_train_test_tabular(Xy_aug, label_col=\"label\")\n",
    "\n",
    "rare_hgb.fit(X_tr_hgb)          # fit on TRAIN ONLY\n",
    "X_tr2_hgb = rare_hgb.transform(X_tr_hgb)\n",
    "X_te2_hgb = rare_hgb.transform(X_te_hgb)\n",
    "\n",
    "assert list(X_tr2_hgb.columns) == list(X_te2_hgb.columns)\n",
    "print(\"Cols/rels that were kept:\", rare_hgb.keep_cols_)            # kept relations\n",
    "print(\"Cols/rels that were removed:\", rare_hgb.collapsed_cols_)  # collapsed relations\n",
    "print(\"\")\n",
    "\n",
    "X_tr2_hgb = X_tr2_hgb.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
    "X_te2_hgb = X_te2_hgb.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "kept_cols = list(X_tr2_hgb.columns[X_tr2_hgb.var(axis=0) > 1e-12])\n",
    "X_tr2_hgb = X_tr2_hgb[kept_cols]\n",
    "X_te2_hgb = X_te2_hgb[kept_cols]\n",
    "\n",
    "hgb_fin = plns.train_hgb(X_tr2_hgb, y_tr_hgb, max_depth=None, learning_rate=0.06, max_iter=400)\n",
    "\n",
    "report_df, cm, imp_df, metrics = plns.evaluate_hgb(hgb_fin, X_te2_hgb, y_te_hgb, feature_names=list(X_tr2_hgb.columns))\n",
    "\n",
    "print(report_df.round(3))\n",
    "print(cm)\n",
    "print(metrics)\n",
    "print(imp_df.head(15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
