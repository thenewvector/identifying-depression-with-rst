{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d6ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install cliffs-delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899269a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Import\n",
    "# import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "# from collections import Counter\n",
    "\n",
    "# === Define the path to the auxiliary modules ===\n",
    "ROOT = Path.cwd().parent\n",
    "SRC = (ROOT / \"src\").resolve()\n",
    "\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "import importlib\n",
    "import analysis.restructure as restr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7e2ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define the path to the data and the pattern for retrieval ==\n",
    "HOME = Path.home()\n",
    "DATA_DIR = (HOME / \"My Drive\" / \"_VectorData\" / \"projects\" / \"identifying_depression_with_rst\" / \"data\").resolve(strict=True)\n",
    "\n",
    "corpus_path = DATA_DIR / \"interim\"\n",
    "corpus_file = corpus_path / \"preprocesssed_corpora.json\"\n",
    "\n",
    "with open(corpus_file, \"r\") as file:\n",
    "    corpora = json.load(file)\n",
    "\n",
    "diagnoses_path = DATA_DIR / \"interim\"\n",
    "diagnoses_file = diagnoses_path / \"all_diagnoses.json\"\n",
    "\n",
    "with open(diagnoses_file, \"r\") as file:\n",
    "    diagnoses = json.load(file)\n",
    "\n",
    "rst_data_path = DATA_DIR / \"interim\"\n",
    "rst_data_file = rst_data_path / \"rst_data.json\"\n",
    "\n",
    "with open(rst_data_file, \"r\") as file:\n",
    "    rst_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edc8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"all_features\"] = all_features_1\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"all_features_neg\"] = all_features_neg_1\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"all_features_pos\"] = all_features_pos_1\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"relations_pos\"] = relations_pos_1\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"relations_neg\"] = relations_neg_1\n",
    "rst_data.setdefault(CORPUS_NAME_1, {})[\"all_relations\"] = list(all_relations_1)\n",
    "\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"all_features\"] = all_features_2\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"all_features_neg\"] = all_features_neg_2\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"all_features_pos\"] = all_features_pos_2\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"relations_pos\"] = relations_pos_2\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"relations_neg\"] = relations_neg_2\n",
    "rst_data.setdefault(CORPUS_NAME_2, {})[\"all_relations\"] = list(all_relations_2)\n",
    "\"\"\"\n",
    "\n",
    "rst_data[\"ked\"][\"all_relations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f332621",
   "metadata": {},
   "source": [
    "## Restructure the data so it's conducive to stat tests and ML pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case we need to reload the module\n",
    "rst = importlib.reload(restr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e02743",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols_pos_1 = restr.get_data_vectors(rst_data[\"ked\"][\"all_relations\"], rst_data[\"ked\"][\"all_features_pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd099155",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_cols_pos_1[\"Sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078abb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols_neg_1 = restr.get_data_vectors(rst_data[\"ked\"][\"all_relations\"], rst_data[\"ked\"][\"all_features_neg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aff43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols_neg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f7fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_cols_neg_1[\"Sequence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f348b4",
   "metadata": {},
   "source": [
    "## Stat Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Iterable, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu, iqr\n",
    "from cliffs_delta import cliffs_delta\n",
    "\n",
    "def test_features(\n",
    "    depressed: Dict[str, List[float]],\n",
    "    healthy: Dict[str, List[float]],\n",
    "    features: Optional[Iterable[str]] = None,  # if None: test all overlapping keys\n",
    "    exclude: Optional[Iterable[str]] = None,   # keys to skip\n",
    "    correction: Optional[str] = \"fdr_bh\",      # \"fdr_bh\", \"bonferroni\", or None\n",
    "    decimals: int = 3,\n",
    "    min_n: int = 2,                            # min per-group samples to test a feature\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Mann–Whitney + Cliff's delta for each overlapping feature (column) in the two dicts.\n",
    "    Works with the output from `get_data_vectors(...)`.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- choose candidate features\n",
    "    keys_dep = set(depressed.keys())\n",
    "    keys_hlt = set(healthy.keys())\n",
    "    candidates = set(features) if features is not None else (keys_dep & keys_hlt)\n",
    "    if exclude:\n",
    "        candidates -= set(exclude)\n",
    "\n",
    "    rows: List[Dict] = []\n",
    "\n",
    "    for feat in sorted(candidates):\n",
    "        dep_vals = np.asarray(depressed.get(feat, []), dtype=float)\n",
    "        hlt_vals = np.asarray(healthy.get(feat, []), dtype=float)\n",
    "\n",
    "        # drop NaNs/Infs\n",
    "        dep = dep_vals[np.isfinite(dep_vals)]\n",
    "        hlt = hlt_vals[np.isfinite(hlt_vals)]\n",
    "\n",
    "        if len(dep) < min_n or len(hlt) < min_n:\n",
    "            continue\n",
    "\n",
    "        # Mann–Whitney (two-sided)\n",
    "        try:\n",
    "            u_stat, p_raw = mannwhitneyu(dep, hlt, alternative=\"two-sided\")\n",
    "        except ValueError:\n",
    "            # identical distributions or all ties may raise in older SciPy—fallback\n",
    "            u_stat, p_raw = np.nan, 1.0\n",
    "\n",
    "        # Cliff's delta\n",
    "        try:\n",
    "            delta, size = cliffs_delta(dep.tolist(), hlt.tolist())\n",
    "        except Exception:\n",
    "            delta, size = np.nan, \"negligible\"\n",
    "\n",
    "        rows.append({\n",
    "            \"Feature\": feat,\n",
    "            \"Median_Depressed\": float(np.median(dep)),\n",
    "            \"Median_Healthy\":  float(np.median(hlt)),\n",
    "            \"IQR_Depressed\":   float(iqr(dep)) if len(dep) > 1 else 0.0,\n",
    "            \"IQR_Healthy\":     float(iqr(hlt)) if len(hlt) > 1 else 0.0,\n",
    "            \"Min_Depressed\":   float(np.min(dep)),\n",
    "            \"Min_Healthy\":     float(np.min(hlt)),\n",
    "            \"Max_Depressed\":   float(np.max(dep)),\n",
    "            \"Max_Healthy\":     float(np.max(hlt)),\n",
    "            \"MannWhitney_U\":   float(u_stat),\n",
    "            \"p_raw\":           float(p_raw),\n",
    "            \"Cliffs_Delta\":    float(delta),\n",
    "            \"Effect_Size\":     size,\n",
    "            \"n_dep\":           int(len(dep)),\n",
    "            \"n_healthy\":       int(len(hlt)),\n",
    "        })\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"Feature\",\"Median_Depressed\",\"Median_Healthy\",\"IQR_Depressed\",\"IQR_Healthy\",\n",
    "            \"Min_Depressed\",\"Min_Healthy\",\"Max_Depressed\",\"Max_Healthy\",\n",
    "            \"MannWhitney_U\",\"p_raw\",\"p_adj\",\"reject\",\"Cliffs_Delta\",\"Effect_Size\",\n",
    "            \"n_dep\",\"n_healthy\"\n",
    "        ])\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # multiple comparison correction\n",
    "    if correction is not None:\n",
    "        try:\n",
    "            from statsmodels.stats.multitest import multipletests\n",
    "            reject, p_adj, _, _ = multipletests(df[\"p_raw\"].values, method=correction)\n",
    "        except Exception:\n",
    "            if correction.lower() == \"bonferroni\":\n",
    "                m = len(df)\n",
    "                p_adj = np.minimum(df[\"p_raw\"].values * m, 1.0)\n",
    "                reject = p_adj < 0.05\n",
    "            else:\n",
    "                # no statsmodels → leave raw p-values\n",
    "                p_adj = df[\"p_raw\"].values\n",
    "                reject = p_adj < 0.05\n",
    "        df[\"p_adj\"] = p_adj\n",
    "        df[\"reject\"] = reject\n",
    "    else:\n",
    "        df[\"p_adj\"] = df[\"p_raw\"].values\n",
    "        df[\"reject\"] = df[\"p_adj\"] < 0.05\n",
    "\n",
    "    # pretty rounding\n",
    "    num_cols = [\n",
    "        \"Median_Depressed\",\"Median_Healthy\",\"IQR_Depressed\",\"IQR_Healthy\",\n",
    "        \"Min_Depressed\",\"Min_Healthy\",\"Max_Depressed\",\"Max_Healthy\",\n",
    "        \"MannWhitney_U\",\"p_raw\",\"p_adj\",\"Cliffs_Delta\"\n",
    "    ]\n",
    "    for c in num_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(float).round(decimals)\n",
    "\n",
    "    # sort by adjusted p then |delta|\n",
    "    df[\"abs_delta\"] = df[\"Cliffs_Delta\"].abs()\n",
    "    df = df.sort_values([\"p_adj\", \"abs_delta\"], ascending=[True, False]).drop(columns=[\"abs_delta\"]).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7abda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = test_features(data_cols_pos_1, data_cols_neg_1, correction=\"fdr_bh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
